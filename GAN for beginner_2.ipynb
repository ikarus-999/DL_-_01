{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam,SGD\nimport keras\nfrom keras import layers\nimport matplotlib.pyplot as plt\nimport sys\nimport numpy as np\nfrom keras.preprocessing import image\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\ndatasets_dir = join(cache_dir, 'datasets') # /cifar-10-batches-py\nif not exists(datasets_dir):\n    makedirs(datasets_dir)\n\n\n!cp ../input/cifar-10-python.tar.gz ~/.keras/datasets/\n!ln -s  ~/.keras/datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz\n!tar xzvf ~/.keras/datasets/cifar-10-python.tar.gz -C ~/.keras/datasets/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n\nX_train = X_train[y_train.flatten() == 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input shape\nimg_rows = 32\nimg_cols = 32\nchannels = 3\n        \nimg_shape = (img_rows, img_cols, channels)        \nlatent_dim = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"height = 32\nwidth = 32\nchannels = 3\n\ngenerator_input = keras.Input(shape=(latent_dim,))\n\n# 입력을 16 × 16 크기의 128개 채널을 가진 특성 맵으로 변환합니다\nx = layers.Dense(128 * 16 * 16)(generator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((16, 16, 128))(x)\n\n# 합성곱 층을 추가합니다\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# 32 × 32 크기로 업샘플링합니다\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# 합성곱 층을 더 추가합니다\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# 32 × 32 크기의 3개 채널을 가진 특성 맵을 생성합니다\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\ngenerator = keras.models.Model(generator_input, x)\ngenerator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator_input = layers.Input(shape=(32, 32, 3))\nx = layers.Conv2D(128, 3)(discriminator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Flatten()(x)\n\n# 드롭아웃 층을 넣는 것이 아주 중요합니다!\nx = layers.Dropout(0.4)(x)\n\n# 분류 층\nx = layers.Dense(1, activation='sigmoid')(x)\n\ndiscriminator = keras.models.Model(discriminator_input, x)\ndiscriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\ndiscriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator.trainable = False\n\ngan_input = keras.Input(shape=(latent_dim,))\ngan_output = discriminator(generator(gan_input))\ngan = keras.models.Model(gan_input, gan_output)\n\ngan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터를 정규화합니다\nX_train = X_train.reshape(\n    (X_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n\niterations = 5000\nbatch_size = 20\nsave_dir = join(datasets_dir, 'gan_images')\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = (X_train - 0.5) / 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nstart = 0\nfor step in range(iterations):\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다 latent spacde (20, 100)\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 가짜 이미지를 디코딩합니다\n    generated_images = generator.predict(random_latent_vectors)\n\n    # 진짜 이미지와 연결합니다\n    stop = start + batch_size\n    real_images = X_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images])\n\n    # 진짜와 가짜 이미지를 구분하여 레이블을 합칩니다\n    labels = np.concatenate([np.ones((batch_size, 1)),\n                             np.zeros((batch_size, 1))])\n    # 레이블에 랜덤 노이즈를 추가합니다. 아주 중요합니다!\n#     labels += 0.05 * np.random.random(labels.shape)\n\n    # fake 1 / real 0 을 구분할 수 있는 discriminator 학습\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n\n    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # 모두 “진짜 이미지\"라고 레이블을 만듭니다\n    misleading_targets = np.zeros((batch_size, 1))\n\n    # generator를 훈련합니다(gan 모델에서 discriminator의 가중치는 동결됩니다)\n    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n    \n    start += batch_size\n    if start > len(X_train) - batch_size:\n      start = 0\n\n    # 중간 중간 저장하고 그래프를 그립니다\n    if step % 500 == 0:\n        # 모델 가중치를 저장합니다\n        gan.save_weights('gan.h5')\n\n        # 측정 지표를 출력합니다\n        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\n        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\n\n        # 생성된 이미지 하나를 저장합니다\n        img = image.array_to_img(generated_images[0] * 255., scale=False)\n        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n\n        # 비교를 위해 진짜 이미지 하나를 저장합니다\n        img = image.array_to_img(real_images[0] * 255., scale=False)\n        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s=X_train[:40]\ns = (s * 0.5) + 0.5\n\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(s):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = np.random.normal(size=(40, latent_dim))\ngenerated_images = generator.predict(noise)\ngenerated_images = 0.5 * generated_images + 0.5\n\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(generated_images):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}